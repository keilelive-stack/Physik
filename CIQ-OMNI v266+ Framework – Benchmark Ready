
# -*- coding: utf-8 -*-
"""
CIQ-OMNI v266+ Framework – Benchmark Ready
==========================================
Eigenständiges, portables Forschungs-Skript mit:
- OMNI-ODE (Orch-OR + IIT + Superposition + KL + logistisches C)
- Energie-pro-Bit E_bit(r,T) (thermisch + quanten + grav.) + Sweep
- 2D "Tropfen-Raumzeit" PDE (A, phi, s) – leichte, stabile Demo
- 266-Knoten Netzwerk (BA-ähnlich mit Fallback)
- Audit-Box (JSON) und CSV/PNG-Exports
- NEU: Leistungs-Benchmark (--benchmark) mit CSV + JSON Ausgabe

Abhängigkeiten: numpy, matplotlib, (optional) scipy, (optional) networkx
"""

from __future__ import annotations
import os, sys, json, math, time, platform, random, csv
from dataclasses import dataclass, asdict
from typing import Callable, Dict, Any, Tuple, Optional, List
import numpy as np
import matplotlib.pyplot as plt

# ---- optionale Imports ----
try:
    from scipy.integrate import solve_ivp  # optional
    SCIPY_OK = True
except Exception:
    SCIPY_OK = False

try:
    import networkx as nx              # optional
    NX_OK = True
except Exception:
    NX_OK = False

# ---------------- Konstanten ----------------
DELTA_CRIT: float = 0.7       # logistischer Schaltbreiten-Fixpunkt
TAU_DECOH: float = 0.0083     # s (8.3 ms)
GAMMA_EXP: float = 2.114      # Exponent für C^gamma im Kopplungsterm
R_LOGISTIC: float = 2.2       # r aus Notiz
K_LOGISTIC: float = 20.0      # K aus Notiz
U_STAR: float = 0.9           # logistischer u* (Schwellwert)

# Naturkonstanten
K_B: float = 1.380649e-23
H_BAR: float = 1.054_571_817e-34
C_LIGHT: float = 299_792_458.0
G_NEWTON: float = 6.67430e-11

# ---------------- Utilities ----------------
def ensure_dir(p: str) -> str:
    os.makedirs(p, exist_ok=True); return p

def timestamp() -> str:
    return time.strftime("%Y%m%d_%H%M%S")

def logistic_switch(u: float, u_star: float = U_STAR, delta: float = DELTA_CRIT) -> float:
    """S_pi(u) = 1/(1+exp(-(u-u*)/Δ))"""
    return 1.0 / (1.0 + math.exp(-(u - u_star) / max(1e-9, delta)))

def e_bit_unified(r_m: float, T_K: float, max_iter: int = 50, tol: float = 1e-12) -> float:
    """
    Implizite Formel (vereinheitlicht):
        E = k_B T ln2 + ħ c /(2 r) + G (E/c^2)^2 / r
    Fixpunkt-Iteration. Bei Divergenz: fallback ohne Grav.-Term.
    """
    thermal = K_B * T_K * math.log(2.0)
    quantum = H_BAR * C_LIGHT / (2.0 * max(r_m, 1e-30))
    E = thermal + quantum  # Startwert
    for _ in range(max_iter):
        grav = G_NEWTON * (E / C_LIGHT**2)**2 / max(r_m, 1e-30)
        E_new = thermal + quantum + grav
        if abs(E_new - E) < tol * max(1.0, abs(E)):
            return E_new
        E = 0.5 * (E + E_new)  # Dämpfung
    return thermal + quantum  # Fallback ohne Gravitation

def p_min_power(r_m: float, T_K: float, bit_rate: float) -> float:
    """P_min = E_bit * bit_rate"""
    return e_bit_unified(r_m, T_K) * max(0.0, bit_rate)

# ---------------- ODE (OMNI) ----------------
@dataclass
class OmniParams:
    a1: float = 2.0     # gains/losses heuristisch mild
    b1: float = 1.0
    a2: float = 1.6
    b2: float = 0.9
    a3: float = 1.8
    b3: float = 0.8
    s_gain: float = 0.7
    s_loss: float = 0.5
    k_kl: float = 1.2
    coupling: float = 0.25       # skaliert α·β im C-Term
    gamma_exp: float = GAMMA_EXP
    r: float = R_LOGISTIC
    K: float = K_LOGISTIC
    u_star: float = U_STAR
    delta: float = DELTA_CRIT
    tau_decoh: float = TAU_DECOH
    T_K: float = 310.0
    r_bit: float = 1e-6          # m (effektiver Informationsradius)
    i_rate_max: float = 1e6      # bits/s (obere Skala)
    seed: int = 42

def rk4_step(f: Callable[[float, np.ndarray], np.ndarray],
             t: float, y: np.ndarray, dt: float) -> np.ndarray:
    k1 = f(t, y)
    k2 = f(t + 0.5*dt, y + 0.5*dt*k1)
    k3 = f(t + 0.5*dt, y + 0.5*dt*k2)
    k4 = f(t + dt, y + dt*k3)
    return y + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)

def omni_rhs(params: OmniParams) -> Callable[[float, np.ndarray], np.ndarray]:
    rng = random.Random(params.seed)
    def f(t: float, x: np.ndarray) -> np.ndarray:
        phi_orch, phi_iit, phi_omni, strength, KL, phi_super, C = x
        S_strength = logistic_switch(strength, params.u_star, params.delta)
        S_omni = logistic_switch(phi_omni, params.u_star, params.delta)

        # Superposition-Fluss als Takt für Informationsrate
        i_rate = max(0.0, min(params.i_rate_max, params.i_rate_max * phi_super))
        P_min = p_min_power(params.r_bit, params.T_K, i_rate)   # W
        # Normiere P_min auf [0, 1] Skala für leichte Rückkopplung (gegen Landauer-Grenze)
        P_norm = P_min / (K_B*params.T_K*params.i_rate_max*math.log(2) + 1e-18)

        # Dynamiken
        dphi_super = (S_strength - phi_super)/params.tau_decoh - 0.15*phi_super*(1.0 - S_strength)
        dphi_orch  = params.a1*phi_super*(1.0 - phi_orch) - params.b1*phi_orch*(1.0 - logistic_switch(phi_iit))
        dphi_iit   = params.a2*phi_orch*(1.0 - phi_iit)   - params.b2*phi_iit*(1.0 - logistic_switch(phi_super))
        dphi_omni  = params.a3*phi_orch*phi_iit*(1.0 - phi_omni) - params.b3*phi_omni*(1.0 - logistic_switch(C/params.K))

        dstrength  = params.s_gain*(C/params.K + 0.25*P_norm) - params.s_loss*strength

        dKL        = - params.k_kl * KL * S_omni + 0.01 * (rng.random() - 0.5)  # winzige Rauschspur

        # Logistic C: dC/dt = r C (1 - C/K) - (αβ) C^γ
        alpha_beta = params.coupling * S_omni
        dC = params.r*C*(1.0 - C/params.K) - alpha_beta * (C**params.gamma_exp)

        return np.array([dphi_orch, dphi_iit, dphi_omni, dstrength, dKL, dphi_super, dC], dtype=float)
    return f

def omni_simulate(params: OmniParams, T: float = 10.0, N: int = 1001,
                  x0: Optional[np.ndarray] = None) -> Dict[str, Any]:
    t = np.linspace(0.0, T, N)
    if x0 is None:
        x0 = np.array([0.05, 0.05, 0.02, 0.10, 1.0, 0.01, 0.5], dtype=float)
    rhs = omni_rhs(params)

    if SCIPY_OK:
        from scipy.integrate import solve_ivp
        sol = solve_ivp(lambda tt, yy: rhs(tt, yy), [t[0], t[-1]], x0, t_eval=t, rtol=1e-6, atol=1e-8, method="RK45")
        Y = sol.y.T
    else:
        # RK4 manuell
        Y = np.zeros((len(t), len(x0)), dtype=float)
        Y[0] = x0
        for i in range(len(t)-1):
            dt = t[i+1]-t[i]
            Y[i+1] = rk4_step(rhs, t[i], Y[i], dt)

    # Compute E_bit (constant for fixed r_bit, T) and P_min(t) based on i_rate(t) = i_rate_max * phi_super(t)
    phi_super_ts = Y[:,5]
    i_rate_ts = np.clip(params.i_rate_max * phi_super_ts, 0.0, params.i_rate_max)
    E_bit_val = e_bit_unified(params.r_bit, params.T_K)
    P_min_ts = E_bit_val * i_rate_ts

    keys = ["phi_orch","phi_iit","phi_omni","strength","KL","phi_super","C"]
    data = { "t": t.tolist(), "E_bit": [float(E_bit_val)]*len(t), "i_rate": i_rate_ts.tolist(), "P_min": P_min_ts.tolist() }
    for j,k in enumerate(keys):
        data[k] = Y[:,j].tolist()

    # Kennzahlen
    metrics = {
        "KL_final": float(Y[-1,4]),
        "phi_omni_final": float(Y[-1,2]),
        "phi_super_mean": float(np.mean(Y[:,5])),
        "C_final": float(Y[-1,6]),
        "E_bit_J": float(E_bit_val),
        "P_min_mean_W": float(np.mean(P_min_ts)),
        "P_min_peak_W": float(np.max(P_min_ts))
    }
    return {"t": t, "Y": Y, "keys": keys, "data": data, "metrics": metrics, "params": asdict(params)}

def plot_series(t: np.ndarray, y: np.ndarray, label: str, path: str):
    plt.figure()
    plt.plot(t, y)
    plt.xlabel("t [s]")
    plt.ylabel(label)
    plt.title(label)
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

# ---------------- PDE (Tropfen-Raumzeit Lite) ----------------
@dataclass
class PdeParams:
    nx: int = 64
    ny: int = 64
    steps: int = 60
    dx: float = 1.0
    dy: float = 1.0
    dt: float = 0.05
    D_A: float = 0.6
    D_phi: float = 0.3
    D_s: float = 0.2
    lam_A: float = 0.05
    lam_s: float = 0.05
    sigma_phi: float = 0.4
    k_eq: float = 2.0

def laplacian(Z: np.ndarray, dx: float, dy: float) -> np.ndarray:
    return (
        (np.roll(Z, 1, 0) - 2*Z + np.roll(Z, -1, 0)) / (dx*dx) +
        (np.roll(Z, 1, 1) - 2*Z + np.roll(Z, -1, 1)) / (dy*dy)
    )

def phi_eq_from_A(A: np.ndarray, k_eq: float) -> np.ndarray:
    # Gasphase bei großem A -> phi_eq ~ 0; solide bei kleinem A -> phi_eq ~ 1
    return 1.0 / (1.0 + k_eq * (A*A))

def pde_demo(params: PdeParams, strength_series: Optional[np.ndarray] = None) -> Dict[str, Any]:
    nx, ny = params.nx, params.ny
    A = np.zeros((nx, ny), dtype=float)
    phi = np.ones((nx, ny), dtype=float) * 0.9  # Start eher "geordnet"
    s = np.zeros((nx, ny), dtype=float)

    # zentraler "Impuls"
    X, Y = np.meshgrid(np.arange(ny), np.arange(nx))
    cx, cy = nx//2, ny//2
    A += np.exp(-(((X-cy)**2 + (Y-cx)**2)/(2*(0.12*nx)**2)))

    steps = params.steps
    for k in range(steps):
        src = 0.5 * np.exp(-(((X-(cy))**2 + (Y-(cx))**2)/(2*(0.08*nx)**2)))
        if strength_series is not None and len(strength_series) > 0:
            # Dynamische Steuerung des Quellterms durch die ODE-Stärke
            idx = min(k, len(strength_series)-1)
            src *= (0.5 + 0.5 * np.clip(strength_series[idx], 0.0, 1.5))

        # Updates (explizit, stabil weil dt klein)
        A = A + params.dt * (params.D_A * laplacian(A, params.dx, params.dy) - params.lam_A * A + src)
        phi_eq = phi_eq_from_A(A, params.k_eq)
        phi = phi + params.dt * (params.D_phi * laplacian(phi, params.dx, params.dy) + params.sigma_phi*(phi_eq - phi))
        s = s + params.dt * (params.D_s * laplacian(s, params.dx, params.dy) + params.lam_s*(A*A) - 0.02*s)

    # Kennzahlen
    metrics = {
        "A_mean": float(A.mean()),
        "phi_mean": float(phi.mean()),
        "s_mean": float(s.mean()),
        "A_max": float(A.max()),
        "s_max": float(s.max()),
    }
    return {"A": A, "phi": phi, "s": s, "metrics": metrics}

def save_field_png(Z: np.ndarray, title: str, path: str):
    plt.figure()
    plt.imshow(Z, origin="lower", interpolation="nearest")
    plt.title(title)
    plt.axis("off")
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

# ---------------- Netzwerk (266-Knoten, Fallback) ----------------
def generate_ba_like(n: int = 266, m: int = 3, seed: int = 42) -> Dict[str, Any]:
    if NX_OK:
        G = nx.barabasi_albert_graph(n=n, m=m, seed=seed)
        deg = dict(G.degree())
        cent = nx.betweenness_centrality(G)
    else:
        # Minimaler Preferential-Attachment Fallback:
        rng = np.random.default_rng(seed)
        degrees = rng.pareto(a=3.0, size=n) * 1.5 + m
        degrees = np.clip(degrees.astype(int), m, n // 5)
        deg = {i: int(degrees[i]) for i in range(n)}
        cent = {i: float(deg[i])/n for i in range(n)} # Einfache Approximation

    # Kennzahlen
    degrees_arr = np.array(list(deg.values()))
    metrics = {
        "n": n,
        "deg_mean": float(degrees_arr.mean()),
        "deg_max": int(degrees_arr.max()),
        "hubs_over_10": int((degrees_arr>10).sum())
    }
    return {"degrees": degrees_arr, "metrics": metrics}

# ---------------- E_bit Sweep ----------------
def ebit_sweep(r_min: float = 1e-9, r_max: float = 1e-3, n: int = 200, T_K: float = 310.0) -> Dict[str, Any]:
    """Return arrays for r (logspace), E_bit(r), and the two-term components for diagnostics."""
    r_vals = np.logspace(np.log10(r_min), np.log10(r_max), n)
    E_vals, E_th, E_q = [], [], []
    for r in r_vals:
        thermal = K_B * T_K * math.log(2.0)
        quantum = H_BAR * C_LIGHT / (2.0 * r)
        E = e_bit_unified(r, T_K)
        E_th.append(thermal); E_q.append(quantum); E_vals.append(E)
    return {"r": r_vals, "E": np.array(E_vals), "E_thermal": np.array(E_th), "E_quantum": np.array(E_q), "T_K": T_K}

def save_ebit_sweep(out_dir: str, sweep: Dict[str, Any]):
    csv_path = os.path.join(out_dir, "e_bit_vs_r.csv")
    with open(csv_path, "w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["r_m","E_bit_J","E_thermal_J","E_quantum_J","T_K"])
        for r, E, Eth, Eq in zip(sweep["r"], sweep["E"], sweep["E_thermal"], sweep["E_quantum"]):
            w.writerow([f"{r:.9g}", f"{E:.9g}", f"{Eth:.9g}", f"{Eq:.9g}", f"{sweep['T_K']:.3f}"])
    # Plot
    plt.figure()
    plt.loglog(sweep["r"], sweep["E"], label="E_bit (total)")
    plt.loglog(sweep["r"], sweep["E_thermal"], linestyle="--", label="thermal kT ln2")
    plt.loglog(sweep["r"], sweep["E_quantum"], linestyle=":", label="quantum ħc/2r")
    plt.xlabel("r [m]"); plt.ylabel("E_bit [J]"); plt.title("Energy per bit vs radius")
    plt.legend(); plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "e_bit_vs_r.png"), dpi=150); plt.close()
    return {"csv": csv_path, "png": os.path.join(out_dir, "e_bit_vs_r.png")}

# ---------------- Orchestrator ----------------
@dataclass
class RunConfig:
    out_dir: str
    mode: str = "all"   # "all" | "ode" | "pde" | "net"
    fast: bool = True
    benchmark: bool = False

# ---------------- Benchmark (CSV + JSON) ----------------
def run_benchmark(out_dir: str) -> Dict[str, float]:
    """
    Misst die Rechenzeit aller Hauptmodule und schreibt CSV + JSON:
    - benchmark_results.json
    - benchmark_results.csv
    """
    times: Dict[str, float] = {}
    t0 = time.time()

    # ODE
    t1 = time.time()
    op = OmniParams()
    res_ode = omni_simulate(op, T=6.0, N=801)
    times["t_ode_s"] = time.time() - t1

    # PDE
    t2 = time.time()
    pdp = PdeParams(steps=40)
    _ = pde_demo(pdp, strength_series=res_ode["Y"][:,3])
    times["t_pde_s"] = time.time() - t2

    # E_bit Sweep
    t3 = time.time()
    sweep = ebit_sweep()
    _ = save_ebit_sweep(out_dir, sweep)  # erzeugt zusätzlich CSV/PNG
    times["t_ebit_s"] = time.time() - t3

    # Netzwerk
    t4 = time.time()
    _ = generate_ba_like(n=266, m=3, seed=42)
    times["t_net_s"] = time.time() - t4

    times["t_total_s"] = time.time() - t0

    # JSON schreiben
    json_path = os.path.join(out_dir, "benchmark_results.json")
    with open(json_path, "w") as f:
        json.dump(times, f, indent=2)

    # CSV schreiben
    csv_path = os.path.join(out_dir, "benchmark_results.csv")
    with open(csv_path, "w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["metric","seconds"])
        for k, v in times.items():
            w.writerow([k, f"{v:.6f}"])

    # Konsolen-Report
    print("\n=== CIQ-OMNI v266+ BENCHMARK ===")
    print(f"OMNI-ODE:    {times['t_ode_s']:.3f} s")
    print(f"PDE Tropfen: {times['t_pde_s']:.3f} s")
    print(f"E_bit Sweep: {times['t_ebit_s']:.3f} s")
    print(f"Netzwerk:    {times['t_net_s']:.3f} s")
    print("------------------------------")
    print(f"GESAMTZEIT:  {times['t_total_s']:.3f} s")
    print("================================\n")

    return times

# --------------- CLI ---------------
def main(argv=None):
    import argparse
    parser = argparse.ArgumentParser(description="CIQ‑OMNI v266+ Framework – Benchmark Ready")
    default_out_dir = os.path.join(os.getcwd(), f"ciq_ultimate_run_{time.strftime('%Y%m%d_%H%M%S')}")
    parser.add_argument("--out", default=default_out_dir, help="Ausgabeordner")
    parser.add_argument("--mode", choices=["all","ode","pde","net"], default="all")
    parser.add_argument("--fast", action="store_true", help="schneller Demolauf")
    parser.add_argument("--ebit-sweep", action="store_true", help="nur E_bit vs r Sweep ausgeben")
    parser.add_argument("--benchmark", action="store_true", help="Leistungs-Benchmark ausführen (CSV + JSON)")
    args = parser.parse_args(argv)

    out_dir = ensure_dir(args.out)
    cfg = RunConfig(out_dir=out_dir, mode=args.mode, fast=args.fast, benchmark=args.benchmark)
    print(f"CIQ‑OMNI v266+ startet in Ordner: {cfg.out_dir}")

    # ODE
    if args.mode in ("all","ode"):
        print("-> Starte OMNI‑ODE Simulation...")
        op = OmniParams()
        odeN = 801 if args.fast else 2001
        odeT = 6.0 if args.fast else 12.0
        res_ode = omni_simulate(op, T=odeT, N=odeN)

        # CSV (mit E_bit, i_rate, P_min + Kernvariablen)
        csv_path = os.path.join(cfg.out_dir, "omni_timeseries.csv")
        keys = ["t","E_bit","i_rate","P_min"] + res_ode["keys"]
        with open(csv_path, "w", newline="") as f:
            w = csv.writer(f)
            w.writerow(keys)
            for i in range(len(res_ode["t"])):
                row = [res_ode["t"][i], res_ode["data"]["E_bit"][i], res_ode["data"]["i_rate"][i], res_ode["data"]["P_min"][i]] + [res_ode["Y"][i,j] for j in range(len(res_ode["keys"]))]
                w.writerow([f"{v:.9g}" if isinstance(v, (float, np.floating)) else v for v in row])

        # Plots
        plot_series(res_ode["t"], res_ode["Y"][:,2], "phi_omni", os.path.join(cfg.out_dir, "phi_omni.png"))
        plot_series(res_ode["t"], res_ode["Y"][:,4], "KL", os.path.join(cfg.out_dir, "KL.png"))
        plot_series(res_ode["t"], res_ode["Y"][:,6], "C", os.path.join(cfg.out_dir, "C.png"))
        plot_series(res_ode["t"], np.array(res_ode["data"]["P_min"]), "P_min [W]", os.path.join(cfg.out_dir, "P_min.png"))
        plot_series(res_ode["t"], np.array(res_ode["data"]["E_bit"]), "E_bit [J]", os.path.join(cfg.out_dir, "E_bit.png"))

    # PDE
    if args.mode in ("all","pde"):
        print("-> Starte PDE (Tropfen‑Raumzeit) Simulation...")
        strength_series = res_ode["Y"][:,3] if (args.mode == "all" and 'res_ode' in locals()) else None
        pdp = PdeParams(steps=40 if args.fast else 90)
        res_pde = pde_demo(pdp, strength_series=strength_series)
        save_field_png(res_pde["A"], "A (Fluktuation)", os.path.join(cfg.out_dir, "pde_A.png"))
        save_field_png(res_pde["phi"], "phi (Ordnungsparameter)", os.path.join(cfg.out_dir, "pde_phi.png"))
        save_field_png(res_pde["s"], "s (Entropiedichte)", os.path.join(cfg.out_dir, "pde_s.png"))

    # Optional E_bit sweep
    if args.ebit_sweep or args.mode == "all":
        print("-> Starte E_bit Sweep (Energiegrenzen)...")
        sweep = ebit_sweep()
        save_ebit_sweep(cfg.out_dir, sweep)

    # Network
    if args.mode in ("all","net"):
        print("-> Generiere Barabási‑Albert‑ähnliches Netzwerk...")
        res_net = generate_ba_like(n=266, m=3, seed=42)
        # Gradverteilung als einfacher Plot
        plt.figure()
        plt.hist(res_net["degrees"], bins=20)
        plt.xlabel("Grad")
        plt.ylabel("Häufigkeit")
        plt.title("Gradverteilung (n=266)")
        plt.tight_layout()
        plt.savefig(os.path.join(cfg.out_dir, "net_degree_hist.png"), dpi=150)
        plt.close()

    # Audit
    if args.mode == "all":
        audit = {
            "time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "platform": platform.platform(),
            "python": sys.version.split()[0],
            "mode": args.mode,
            "fast": bool(args.fast),
            "ode_metrics": res_ode["metrics"] if 'res_ode' in locals() else "N/A",
            "constants": {
                "DELTA_CRIT": DELTA_CRIT, "TAU_DECOH": TAU_DECOH,
                "GAMMA_EXP": GAMMA_EXP, "R_LOGISTIC": R_LOGISTIC, "K_LOGISTIC": K_LOGISTIC,
                "U_STAR": U_STAR
            },
        }
        if 'res_pde' in locals():
            audit["pde_metrics"] = res_pde["metrics"]
        if 'res_net' in locals():
            audit["net_metrics"] = res_net["metrics"]

        with open(os.path.join(cfg.out_dir, "audit.json"), "w") as f:
            json.dump(audit, f, indent=2)
        print("\n-> Alle Simulationen abgeschlossen. Audit-Log gespeichert.")

    # Benchmark
    if args.benchmark:
        run_benchmark(cfg.out_dir)

if __name__ == "__main__":
    main()

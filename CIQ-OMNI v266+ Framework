# -*- coding: utf-8 -*-
"""
CIQ Ultimate Simulator v266+
============================
Author: Tobias Keilholz, keile.live@gmail.com

Ein einziges, eigenständiges Python-Skript, das die Kernideen des CIQ-Frameworks bündelt:
- OMNI-ODE (Orch-OR + IIT + Superposition + KL-Konvergenz + logistisches C-System)
- Energie-pro-Bit (vereinheitlicht, thermisch + quanten + grav.) -> P_min-Schätzung
- 2D "Tropfen-Raumzeit" PDE (A, phi, s) – leichte, stabile Demo
- (Optional) 266-Knoten Netzwerk (BA-ähnlich, mit Fallback ohne networkx)
- Audit-JSON + CSV/PNG-Exports in einen Run-Ordner

Keine externen Abhängigkeiten außer: numpy, matplotlib (für PNG), (optional) scipy, (optional) networkx.
Falls scipy nicht verfügbar ist, wird ein eigener RK4-Integrator genutzt.
"""

from __future__ import annotations
import os, sys, json, math, time, platform, random
from dataclasses import dataclass, asdict
from typing import Callable, Dict, Any, Tuple
import numpy as np
import matplotlib.pyplot as plt

# --- Opt. imports ---
try:
    from scipy.integrate import solve_ivp  # optional
    SCIPY_OK = True
except Exception:
    SCIPY_OK = False
try:
    import networkx as nx              # optional
    NX_OK = True
except Exception:
    NX_OK = False

# ---------------- Constants (aus deiner Erinnerung / Model-Context) ----------------
DELTA_CRIT: float = 0.7       # logistischer Schaltbreiten-Fixpunkt
TAU_DECOH: float = 0.0083     # s (8.3 ms)
GAMMA_EXP: float = 2.114       # Exponent für C^gamma im Kopplungsterm
R_LOGISTIC: float = 2.2        # r aus Notiz
K_LOGISTIC: float = 20.0       # K aus Notiz
U_STAR: float = 0.9            # logistischer u* (Schwellwert)
K_B: float = 1.380649e-23      # Boltzmann
H_BAR: float = 1.054_571_817e-34
C_LIGHT: float = 299_792_458.0
G_NEWTON: float = 6.67430e-11

# ---------------- Utilities ----------------
def ensure_dir(p: str) -> str:
    os.makedirs(p, exist_ok=True); return p

def timestamp() -> str:
    return time.strftime("%Y%m%d_%H%M%S")

def logistic_switch(u: float, u_star: float = U_STAR, delta: float = DELTA_CRIT) -> float:
    """S_pi(u) = 1/(1+exp(-(u-u*)/Δ))"""
    return 1.0 / (1.0 + math.exp(-(u - u_star) / max(1e-9, delta)))

def e_bit_unified(r_m: float, T_K: float, max_iter: int = 50, tol: float = 1e-12) -> float:
    """
    Implizite Formel (vereinheitlicht):
        E = k_B T ln2 + ħ c /(2 r) + G (E/c^2)^2 / r
    Fixpunkt-Iteration. Bei Divergenz: fallback ohne Grav.-Term.
    """
    thermal = K_B * T_K * math.log(2.0)
    quantum = H_BAR * C_LIGHT / (2.0 * max(r_m, 1e-30))
    E = thermal + quantum  # Startwert
    for _ in range(max_iter):
        grav = G_NEWTON * (E / C_LIGHT**2)**2 / max(r_m, 1e-30)
        E_new = thermal + quantum + grav
        if abs(E_new - E) < tol * max(1.0, abs(E)):
            return E_new
        # simple damping
        E = 0.5 * E + 0.5 * E_new
    # Fallback (ohne grav)
    return thermal + quantum

def p_min_power(r_m: float, T_K: float, bit_rate: float) -> float:
    """P_min = E_bit * bit_rate"""
    E = e_bit_unified(r_m, T_K)
    return E * max(0.0, bit_rate)

# ---------------- ODE (OMNI) ----------------
@dataclass
class OmniParams:
    a1: float = 2.0     # gains/losses heuristisch mild
    b1: float = 1.0
    a2: float = 1.6
    b2: float = 0.9
    a3: float = 1.8
    b3: float = 0.8
    s_gain: float = 0.7
    s_loss: float = 0.5
    k_kl: float = 1.2
    coupling: float = 0.25       # skaliert α·β im C-Term
    gamma_exp: float = GAMMA_EXP
    r: float = R_LOGISTIC
    K: float = K_LOGISTIC
    u_star: float = U_STAR
    delta: float = DELTA_CRIT
    tau_decoh: float = TAU_DECOH
    T_K: float = 310.0
    r_bit: float = 1e-6          # m (effektiver Informationsradius)
    i_rate_max: float = 1e6      # bits/s (obere Skala)
    seed: int = 42

def rk4_step(f: Callable[[float, np.ndarray], np.ndarray],
             t: float, y: np.ndarray, dt: float) -> np.ndarray:
    k1 = f(t, y)
    k2 = f(t + 0.5*dt, y + 0.5*dt*k1)
    k3 = f(t + 0.5*dt, y + 0.5*dt*k2)
    k4 = f(t + dt, y + dt*k3)
    return y + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)

def omni_rhs(params: OmniParams) -> Callable[[float, np.ndarray], np.ndarray]:
    rng = random.Random(params.seed)
    def f(t: float, x: np.ndarray) -> np.ndarray:
        phi_orch, phi_iit, phi_omni, strength, KL, phi_super, C = x
        S_strength = logistic_switch(strength, params.u_star, params.delta)
        S_omni = logistic_switch(phi_omni, params.u_star, params.delta)
        # S_C = logistic_switch(C/params.K, params.u_star, params.delta) # Nicht verwendet

        # Superposition-Fluss als Takt für Informationsrate
        i_rate = max(0.0, min(params.i_rate_max, params.i_rate_max * phi_super))
        P_min = p_min_power(params.r_bit, params.T_K, i_rate)   # W
        # Normiere P_min auf [0, 1] Skala für leichte Rückkopplung
        P_norm = P_min / (K_B*params.T_K*params.i_rate_max*math.log(2) + 1e-18) # Normiert gegen Landauer-Grenze P_max

        # Dynamiken
        dphi_super = (S_strength - phi_super)/params.tau_decoh - 0.15*phi_super*(1.0 - S_strength)
        dphi_orch  = params.a1*phi_super*(1.0 - phi_orch) - params.b1*phi_orch*(1.0 - logistic_switch(phi_iit))
        dphi_iit   = params.a2*phi_orch*(1.0 - phi_iit)   - params.b2*phi_iit*(1.0 - logistic_switch(phi_super))
        dphi_omni  = params.a3*phi_orch*phi_iit*(1.0 - phi_omni) - params.b3*phi_omni*(1.0 - logistic_switch(C/params.K))

        dstrength  = params.s_gain*(C/params.K + 0.25*P_norm) - params.s_loss*strength

        dKL        = - params.k_kl * KL * S_omni + 0.01 * (rng.random() - 0.5)  # winzige Rauschspur

        # Logistic C: dC/dt = r C (1 - C/K) - (αβ) C^γ
        alpha_beta = params.coupling * S_omni
        dC = params.r*C*(1.0 - C/params.K) - alpha_beta * (C**params.gamma_exp)

        return np.array([dphi_orch, dphi_iit, dphi_omni, dstrength, dKL, dphi_super, dC], dtype=float)
    return f

def omni_simulate(params: OmniParams, T: float = 10.0, N: int = 1001,
                  x0: np.ndarray | None = None) -> Dict[str, Any]:
    t = np.linspace(0.0, T, N)
    if x0 is None:
        x0 = np.array([0.05, 0.05, 0.02, 0.10, 1.0, 0.01, 0.5], dtype=float)
    rhs = omni_rhs(params)

    if SCIPY_OK:
        sol = solve_ivp(lambda tt, yy: rhs(tt, yy), [t[0], t[-1]], x0, t_eval=t, rtol=1e-6, atol=1e-8, method="RK45")
        Y = sol.y.T
    else:
        # RK4 manuell
        Y = np.zeros((len(t), len(x0)), dtype=float)
        Y[0] = x0
        for i in range(len(t)-1):
            dt = t[i+1]-t[i]
            Y[i+1] = rk4_step(rhs, t[i], Y[i], dt)

    # Compute E_bit (constant for fixed r_bit, T) and P_min(t) based on i_rate(t) = i_rate_max * phi_super(t)
    phi_super_ts = Y[:,5]
    i_rate_ts = np.clip(params.i_rate_max * phi_super_ts, 0.0, params.i_rate_max)
    E_bit_val = e_bit_unified(params.r_bit, params.T_K)
    P_min_ts = E_bit_val * i_rate_ts

    keys = ["phi_orch","phi_iit","phi_omni","strength","KL","phi_super","C"]
    data = { "t": t.tolist(), "E_bit": [float(E_bit_val)]*len(t), "i_rate": i_rate_ts.tolist(), "P_min": P_min_ts.tolist() }
    for j,k in enumerate(keys):
        data[k] = Y[:,j].tolist()

    # Kennzahlen
    metrics = {
        "KL_final": float(Y[-1,4]),
        "phi_omni_final": float(Y[-1,2]),
        "phi_super_mean": float(np.mean(Y[:,5])),
        "C_final": float(Y[-1,6]),
        "E_bit_J": float(E_bit_val),
        "P_min_mean_W": float(np.mean(P_min_ts)),
        "P_min_peak_W": float(np.max(P_min_ts))
    }
    return {"t": t, "Y": Y, "keys": keys, "data": data, "metrics": metrics, "params": asdict(params)}

def plot_series(t: np.ndarray, y: np.ndarray, label: str, path: str):
    plt.figure()
    plt.plot(t, y)
    plt.xlabel("t [s]")
    plt.ylabel(label)
    plt.title(label)
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

# ---------------- PDE (Tropfen-Raumzeit Lite) ----------------
@dataclass
class PdeParams:
    nx: int = 64
    ny: int = 64
    steps: int = 60
    dx: float = 1.0
    dy: float = 1.0
    dt: float = 0.05
    D_A: float = 0.6
    D_phi: float = 0.3
    D_s: float = 0.2
    lam_A: float = 0.05
    lam_s: float = 0.05
    sigma_phi: float = 0.4
    k_eq: float = 2.0

def laplacian(Z: np.ndarray, dx: float, dy: float) -> np.ndarray:
    return (
        (np.roll(Z, 1, 0) - 2*Z + np.roll(Z, -1, 0)) / (dx*dx) +
        (np.roll(Z, 1, 1) - 2*Z + np.roll(Z, -1, 1)) / (dy*dy)
    )

def phi_eq_from_A(A: np.ndarray, k_eq: float) -> np.ndarray:
    # Gasphase bei großem A -> phi_eq ~ 0; solide bei kleinem A -> phi_eq ~ 1
    return 1.0 / (1.0 + k_eq * (A*A))

def pde_demo(params: PdeParams, strength_series: np.ndarray | None = None) -> Dict[str, Any]:
    nx, ny = params.nx, params.ny
    A = np.zeros((nx, ny), dtype=float)
    phi = np.ones((nx, ny), dtype=float) * 0.9  # Start eher "geordnet"
    s = np.zeros((nx, ny), dtype=float)

    # zentraler "Impuls"
    X, Y = np.meshgrid(np.arange(ny), np.arange(nx))
    cx, cy = nx//2, ny//2
    A += np.exp(-(((X-cy)**2 + (Y-cx)**2)/(2*(0.12*nx)**2)))

    frames = []
    steps = params.steps
    for k in range(steps):
        src = 0.5 * np.exp(-(((X-(cy))**2 + (Y-(cx))**2)/(2*(0.08*nx)**2)))
        if strength_series is not None and len(strength_series) > 0:
            # Dynamische Steuerung des Quellterms durch die ODE-Stärke
            idx = min(k, len(strength_series)-1)
            src *= (0.5 + 0.5 * np.clip(strength_series[idx], 0.0, 1.5))

        # Updates (explizit, stabil weil dt klein)
        A = A + params.dt * (params.D_A * laplacian(A, params.dx, params.dy) - params.lam_A * A + src)
        phi_eq = phi_eq_from_A(A, params.k_eq)
        phi = phi + params.dt * (params.D_phi * laplacian(phi, params.dx, params.dy) + params.sigma_phi*(phi_eq - phi))
        s = s + params.dt * (params.D_s * laplacian(s, params.dx, params.dy) + params.lam_s*(A*A) - 0.02*s)

        if k in (steps-1,):   # finaler Frame
            frames.append((A.copy(), phi.copy(), s.copy()))

    # Kennzahlen
    metrics = {
        "A_mean": float(A.mean()),
        "phi_mean": float(phi.mean()),
        "s_mean": float(s.mean()),
        "A_max": float(A.max()),
        "s_max": float(s.max()),
    }
    return {"A": A, "phi": phi, "s": s, "frames": frames, "metrics": metrics}

def save_field_png(Z: np.ndarray, title: str, path: str):
    plt.figure()
    plt.imshow(Z, origin="lower", interpolation="nearest")
    plt.title(title)
    plt.axis("off")
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

# ---------------- Netzwerk (266-Knoten, Fallback) ----------------
def generate_ba_like(n: int = 266, m: int = 3, seed: int = 42) -> Dict[str, Any]:
    if NX_OK:
        G = nx.barabasi_albert_graph(n=n, m=m, seed=seed)
        deg = dict(G.degree())
        cent = nx.betweenness_centrality(G)
    else:
        # Minimaler Preferential-Attachment Fallback (für Konsistenz)
        rng = random.Random(seed)
        edges = []
        # Fallback-Logik (wie im Originalskript angedeutet)
        # ... Hier würde die detaillierte manuelle Implementierung stehen

        # Für die Demo: Einfache Erzeugung von Grad-Daten
        degrees = np.random.pareto(a=3.0, size=n) * 1.5 + m
        degrees = np.clip(degrees.astype(int), m, n // 5)
        deg = {i: degrees[i] for i in range(n)}
        cent = {i: float(deg[i])/n for i in range(n)} # Einfache Approximation

    # Kennzahlen
    degrees = np.array(list(deg.values()))
    metrics = {
        "n": n,
        "deg_mean": float(degrees.mean()),
        "deg_max": int(degrees.max()),
        "hubs_over_10": int((degrees>10).sum())
    }
    return {"degrees": degrees, "metrics": metrics}



def ebit_sweep(r_min: float = 1e-9, r_max: float = 1e-3, n: int = 200, T_K: float = 310.0) -> Dict[str, Any]:
    """Return arrays for r (logspace), E_bit(r), and the two-term components for diagnostics."""
    r_vals = np.logspace(np.log10(r_min), np.log10(r_max), n)
    E_vals, E_th, E_q = [], [], []
    for r in r_vals:
        thermal = K_B * T_K * math.log(2.0)
        quantum = H_BAR * C_LIGHT / (2.0 * r)
        E = e_bit_unified(r, T_K)
        E_th.append(thermal); E_q.append(quantum); E_vals.append(E)
    return {"r": r_vals, "E": np.array(E_vals), "E_thermal": np.array(E_th), "E_quantum": np.array(E_q), "T_K": T_K}

def save_ebit_sweep(out_dir: str, sweep: Dict[str, Any]):
    csv = os.path.join(out_dir, "e_bit_vs_r.csv")
    with open(csv, "w") as f:
        f.write("r_m,E_bit_J,E_thermal_J,E_quantum_J,T_K\n")
        for r, E, Eth, Eq in zip(sweep["r"], sweep["E"], sweep["E_thermal"], sweep["E_quantum"]):
            # E_quantum und E_thermal sind die nicht-gravitativen Teile
            f.write(f"{r:.9g},{E:.9g},{Eth:.9g},{Eq:.9g},{sweep['T_K']:.3f}\n")
    # Plot
    plt.figure()
    plt.loglog(sweep["r"], sweep["E"], label="E_bit (total)")
    plt.loglog(sweep["r"], sweep["E_thermal"], linestyle="--", label="thermal kT ln2")
    plt.loglog(sweep["r"], sweep["E_quantum"], linestyle=":", label="quantum ħc/2r")
    plt.xlabel("r [m]"); plt.ylabel("E_bit [J]"); plt.title("Energy per bit vs radius")
    plt.legend(); plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "e_bit_vs_r.png"), dpi=150); plt.close()
    return {"csv": csv, "png": os.path.join(out_dir, "e_bit_vs_r.png")}

# ---------------- Orchestrator ----------------
@dataclass
class RunConfig:
    out_dir: str
    mode: str = "all"   # "all" | "ode" | "pde" | "net"
    fast: bool = True

# --------------- CLI ---------------

def main(argv=None):
    import argparse
    parser = argparse.ArgumentParser(description="CIQ Ultimate Simulator v266+")
    
    # Erzeuge einen eindeutigen Ordnernamen für den Run
    default_out_dir = os.path.join(os.getcwd(), f"ciq_ultimate_run_{time.strftime('%Y%m%d_%H%M%S')}")
    
    parser.add_argument("--out", default=default_out_dir,
                        help="Ausgabeordner")
    parser.add_argument("--mode", choices=["all","ode","pde","net"], default="all")
    parser.add_argument("--fast", action="store_true", help="schneller Demolauf")
    parser.add_argument("--ebit-sweep", action="store_true", help="E_bit vs r sweep ausgeben")
    args = parser.parse_args(argv)

    os.makedirs(args.out, exist_ok=True)
    cfg = RunConfig(out_dir=args.out, mode=args.mode, fast=args.fast)
    print(f"CIQ Ultimate Simulator startet in Ordner: {cfg.out_dir}")

    # ODE
    if args.mode in ("all","ode"):
        print("-> Starte OMNI-ODE Simulation...")
        op = OmniParams()
        odeN = 801 if args.fast else 2001
        odeT = 6.0 if args.fast else 12.0
        res_ode = omni_simulate(op, T=odeT, N=odeN)
        
        # Speichern der CSV (mit E_bit, i_rate, P_min)
        csv_path = os.path.join(cfg.out_dir, "omni_timeseries.csv")
        keys = ["t","E_bit","i_rate","P_min"] + res_ode["keys"]
        with open(csv_path, "w") as f:
            f.write(",".join(keys) + "\n")
            for i in range(len(res_ode["t"])):
                row = [res_ode["t"][i], res_ode["data"]["E_bit"][i], res_ode["data"]["i_rate"][i], res_ode["data"]["P_min"][i]] + [res_ode["Y"][i,j] for j in range(len(res_ode["keys"]))]
                f.write(",".join(f"{v:.9g}" for v in row) + "\n")
        
        # Speichern der Plots
        plot_series(res_ode["t"], res_ode["Y"][:,2], "phi_omni", os.path.join(cfg.out_dir, "phi_omni.png"))
        plot_series(res_ode["t"], res_ode["Y"][:,4], "KL", os.path.join(cfg.out_dir, "KL.png"))
        plot_series(res_ode["t"], res_ode["Y"][:,6], "C", os.path.join(cfg.out_dir, "C.png"))
        plot_series(res_ode["t"], np.array(res_ode["data"]["P_min"]), "P_min [W]", os.path.join(cfg.out_dir, "P_min.png"))
        plot_series(res_ode["t"], np.array(res_ode["data"]["E_bit"]), "E_bit [J]", os.path.join(cfg.out_dir, "E_bit.png"))

    # PDE
    if args.mode in ("all","pde"):
        print("-> Starte PDE (Tropfen-Raumzeit) Simulation...")
        # Stärke aus ODE laden falls vorhanden
        strength_series = None
        if args.mode == "all" and 'res_ode' in locals():
            # Verwende direkt das ODE-Resultat
            strength_series = res_ode["Y"][:,3]
        elif args.mode == "pde":
             # Versuche, Stärke aus einer existierenden CSV zu laden
            try:
                import csv
                str_series = []
                csv_path = os.path.join(cfg.out_dir, "omni_timeseries.csv")
                with open(csv_path, "r") as f:
                    rdr = csv.reader(f)
                    hdr = next(rdr)
                    idx_strength = hdr.index("strength")
                    for row in rdr:
                        str_series.append(float(row[idx_strength]))
                strength_series = np.array(str_series)
            except Exception:
                print("   [Warnung] Konnte Stärke-Serie nicht aus CSV laden. Verwende konstante Stärke.")
                pass

        pdp = PdeParams(steps=40 if args.fast else 90)
        res_pde = pde_demo(pdp, strength_series=strength_series)
        save_field_png(res_pde["A"], "A (Fluktuation)", os.path.join(cfg.out_dir, "pde_A.png"))
        save_field_png(res_pde["phi"], "phi (Ordnungsparameter)", os.path.join(cfg.out_dir, "pde_phi.png"))
        save_field_png(res_pde["s"], "s (Entropiedichte)", os.path.join(cfg.out_dir, "pde_s.png"))

    # Optional E_bit sweep
    if args.ebit_sweep or args.mode == "all":
        print("-> Starte E_bit Sweep (Energiegrenzen)...")
        sweep = ebit_sweep()
        save_ebit_sweep(cfg.out_dir, sweep)

    # Network
    if args.mode in ("all","net"):
        print("-> Generiere Barabási-Albert-ähnliches Netzwerk...")
        res_net = generate_ba_like(n=266, m=3, seed=42)
        # Gradverteilung als einfacher Plot
        plt.figure()
        plt.hist(res_net["degrees"], bins=20)
        plt.xlabel("Grad")
        plt.ylabel("Häufigkeit")
        plt.title("Gradverteilung (n=266)")
        plt.tight_layout()
        plt.savefig(os.path.join(cfg.out_dir, "net_degree_hist.png"), dpi=150)
        plt.close()

    if args.mode == "all":
        # Audit am Ende neu zusammenfassen
        audit = {
            "time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "platform": platform.platform(),
            "python": sys.version.split()[0],
            "mode": args.mode,
            "fast": bool(args.fast),
            "ode_metrics": res_ode["metrics"] if 'res_ode' in locals() else "N/A",
            "pde_metrics": res_pde["metrics"] if 'res_pde' in locals() else "N/A",
            "net_metrics": res_net["metrics"] if 'res_net' in locals() else "N/A",
            "constants": {
                "DELTA_CRIT": DELTA_CRIT, "TAU_DECOH": TAU_DECOH,
                "GAMMA_EXP": GAMMA_EXP, "R_LOGISTIC": R_LOGISTIC, "K_LOGISTIC": K_LOGISTIC,
                "U_STAR": U_STAR
            },
        }
        with open(os.path.join(cfg.out_dir, "audit.json"), "w") as f:
            json.dump(audit, f, indent=2)
        print("\n-> Alle Simulationen abgeschlossen. Audit-Log gespeichert.")


if __name__ == "__main__":
    main()
